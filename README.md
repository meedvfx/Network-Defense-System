# üõ°Ô∏è Network Defense System (NDS)

Plateforme SOC (Security Operations Center) orient√©e **d√©tection d‚Äôintrusions r√©seau en temps r√©el**, combinant :
- une cha√Æne de **capture/agr√©gation de flux r√©seau**,
- un pipeline **IA hybride d‚Äôinf√©rence uniquement** (supervis√© + non supervis√© + r√©putation IP),
- un backend **FastAPI asynchrone**,
- un dashboard React temps r√©el,
- un module de **reporting intelligent pilot√© par LLM**.

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.129+-009688?logo=fastapi)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-orange?logo=tensorflow)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-336791?logo=postgresql)
![Redis](https://img.shields.io/badge/Redis-7-DC382D?logo=redis)
![React](https://img.shields.io/badge/React-18-61DAFB?logo=react)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## Table des mati√®res

- [1. Positionnement et p√©rim√®tre](#1-positionnement-et-p√©rim√®tre)
- [2. Architecture syst√®me compl√®te](#2-architecture-syst√®me-compl√®te)
- [3. Structure du d√©p√¥t](#3-structure-du-d√©p√¥t)
- [4. Stack technologique r√©elle](#4-stack-technologique-r√©elle)
- [5. Flux de donn√©es op√©rationnel](#5-flux-de-donn√©es-op√©rationnel)
- [6. Pipeline IA (inf√©rence uniquement)](#6-pipeline-ia-inf√©rence-uniquement)
- [7. Module Reporting LLM](#7-module-reporting-llm)
- [8. Sch√©ma de donn√©es et persistance](#8-sch√©ma-de-donn√©es-et-persistance)
- [9. API backend (routes expos√©es)](#9-api-backend-routes-expos√©es)
- [10. Dashboard React (vues et int√©gration)](#10-dashboard-react-vues-et-int√©gration)
- [11. S√©curit√©, gouvernance et contraintes](#11-s√©curit√©-gouvernance-et-contraintes)
- [12. Installation et ex√©cution](#12-installation-et-ex√©cution)
- [13. Configuration environnement](#13-configuration-environnement)
- [14. Observabilit√© et exploitation](#14-observabilit√©-et-exploitation)
- [15. Limites connues et axes d‚Äôam√©lioration](#15-limites-connues-et-axes-dam√©lioration)
- [16. Documentation compl√©mentaire](#16-documentation-compl√©mentaire)
- [17. Licence](#17-licence)

---

## 1. Positionnement et p√©rim√®tre

### 1.1 Objectif principal

Le projet NDS vise la **d√©tection continue d‚Äôactivit√©s r√©seau malveillantes** via un moteur d√©cisionnel hybride, avec restitution SOC orient√©e exploitation :
- alerting en quasi temps r√©el,
- visualisation consolid√©e (threat score, timeline, carte d‚Äôattaque, distributions),
- g√©n√©ration de rapports analytiques (JSON / Markdown / PDF) enrichis par LLM.

### 1.2 Port√©e fonctionnelle actuelle

- **Capture r√©seau** via Scapy (thread d√©di√© + buffer circulaire).
- **Construction de flux bidirectionnels** (5-tuple canonique) avec timeout.
- **Extraction de features CIC-compatibles** (~80 variables statistiques).
- **Pr√©traitement IA** : validation ‚Üí scaling ‚Üí feature selection.
- **Inf√©rence supervis√©e** (classification multi-classe).
- **Inf√©rence non supervis√©e** (autoencodeur + erreur de reconstruction).
- **Fusion hybride** (poids configur√©s + r√©putation IP).
- **Persistance transactionnelle** en PostgreSQL (flows, scores, alertes, feedback).
- **Diffusion temps r√©el** des alertes via Redis Pub/Sub ‚Üí WebSocket.
- **Reporting SOC assist√© LLM** avec export multi-format.

### 1.3 Hors p√©rim√®tre applicatif direct

- L‚Äôentra√Ænement des mod√®les **n‚Äôest pas ex√©cut√© dans cette application**.
- Le projet charge exclusivement des artefacts pr√©-entra√Æn√©s d√©pos√©s dans `ai/artifacts/`.

---

## 2. Architecture syst√®me compl√®te

```mermaid
flowchart TB
    subgraph UI[Dashboard React - Vite]
      V1[Vue Overview]
      V2[Vue Alertes]
      V3[Vue Trafic]
      V4[Vue Carte]
      V5[Vue Reporting IA]
    end

    subgraph API[Backend FastAPI]
      R1[Routes Detection]
      R2[Routes Alerts]
      R3[Routes Dashboard]
      R4[Routes Geo]
      R5[Routes Models]
      R6[Routes Feedback]
      R7[Routes Reporting]
      WS[WebSocket /ws/alerts]
      SVC[Services metier]
      REP[Repository SQLAlchemy Async]
    end

    subgraph CAP[Pipeline Capture]
      SNF[PacketSniffer Scapy]
      FLW[FlowBuilder]
      FEX[FeatureExtractor]
    end

    subgraph AI[Pipeline IA Inference]
      MLD[ModelLoader]
      PRE[FeaturePipeline]
      SUP[Supervised Predictor]
      UNS[Unsupervised Predictor]
      HBD[Hybrid Decision Engine]
    end

    subgraph DATA[Persistance & Cache]
      PG[(PostgreSQL)]
      RED[(Redis)]
    end

    subgraph REPOR[Reporting Module]
      MET[Metrics Engine]
      TRD[Trend Analysis]
      TIX[Threat Index]
      PRM[Prompt Builder]
      LLM[LLM Engine]
      FMT[Report Formatter]
      PDF[PDF Exporter]
    end

    UI -->|REST /api/*| API
    API --> SVC --> REP --> PG
    SVC --> RED
    SVC --> AI
    SVC --> CAP

    CAP --> AI
    AI --> SVC

    RED --> WS --> UI

    API --> REPOR
    REPOR --> PG
    REPOR --> LLM
    REPOR --> PDF
```

### 2.1 Principes d‚Äôarchitecture observ√©s

- **S√©paration nette des couches** : API / Services / Repository / Capture / IA / Reporting.
- **Asynchronisme backend** : FastAPI + SQLAlchemy async + Redis async.
- **Tol√©rance aux indisponibilit√©s** : fallbacks sur DB/Redis/Geo/LLM selon modules.
- **Conception orient√©e production** : healthcheck, scheduler de r√©tention, dockerisation DB/Redis.

---

## 3. Structure du d√©p√¥t

```text
Network-Defense-System/
‚îú‚îÄ‚îÄ ai/                              # IA inf√©rence uniquement
‚îÇ   ‚îú‚îÄ‚îÄ artifacts/                   # Mod√®les et objets de preprocessing export√©s
‚îÇ   ‚îú‚îÄ‚îÄ config/model_config.py       # Chemins artefacts + seuils/poids inf√©rence
‚îÇ   ‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supervised_predictor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unsupervised_predictor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hybrid_decision_engine.py
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing/
‚îÇ       ‚îú‚îÄ‚îÄ data_validator.py
‚îÇ       ‚îî‚îÄ‚îÄ feature_pipeline.py
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # FastAPI app, lifecycle, middlewares, routes
‚îÇ   ‚îú‚îÄ‚îÄ api/                         # Endpoints REST/WebSocket
‚îÇ   ‚îú‚îÄ‚îÄ core/                        # Config, s√©curit√©, exceptions m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ database/                    # Connexion, ORM, repository, Redis client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrations/initial_schema.sql
‚îÇ   ‚îî‚îÄ‚îÄ services/                    # Logique m√©tier (detection, capture, alert, geo...)
‚îú‚îÄ‚îÄ capture/                         # Sniffer + flow builder + extraction features
‚îú‚îÄ‚îÄ geo/                             # Classification IP + geolocalisation ip-api
‚îú‚îÄ‚îÄ reporting/                       # Pipeline reporting + LLM + export PDF/MD/JSON
‚îú‚îÄ‚îÄ monitoring/                      # Logging centralis√© + m√©triques syst√®me
‚îú‚îÄ‚îÄ dashboard/                       # Frontend React/Vite
‚îú‚îÄ‚îÄ docs/                            # Probl√©matique, entra√Ænement, guide utilisateur
‚îú‚îÄ‚îÄ docker-compose.yml               # PostgreSQL + Redis + Backend (3 services)
‚îú‚îÄ‚îÄ Dockerfile                       # Image backend Python
‚îú‚îÄ‚îÄ .dockerignore                    # Exclusions build Docker
‚îú‚îÄ‚îÄ .env                             # Variables d'environnement
‚îî‚îÄ‚îÄ requirements.txt                 # D√©pendances Python (minimis√©es)
```

---

## 4. Stack technologique r√©elle

> D√©riv√©e de l‚Äôimpl√©mentation effective (`backend/`, `ai/`, `capture/`, `reporting/`, `dashboard/`).

### 4.1 Backend & API

- **FastAPI** (`backend/main.py`) + OpenAPI (Swagger/ReDoc).
- **Pydantic v2 + pydantic-settings** pour la configuration.
- **SlowAPI** (limiter initialis√© dans l‚Äôapplication).
- **Uvicorn** comme serveur ASGI.

### 4.2 Persistance et cache

- **PostgreSQL** (sch√©ma SQL initial + ORM SQLAlchemy 2.0 async).
- **asyncpg** pour connexion async.
- **Redis 7** pour :
  - cache op√©rationnel,
  - compteurs m√©triques,
  - pub/sub alertes temps r√©el,
  - threat score global.

### 4.3 IA & Data

- **TensorFlow / Keras** pour les mod√®les d‚Äôinf√©rence.
- **NumPy** pour le calcul vectoriel.
- **joblib** pour les objets de preprocessing (`scaler`, `encoder`, `feature_selector`, `threshold_stats`).
- **Scikit-learn artefacts** charg√©s c√¥t√© inf√©rence.

### 4.4 Capture et r√©seau

- **Scapy** pour sniffing paquets IP/TCP/UDP.
- Thread de capture d√©di√© + buffer circulaire (`collections.deque`).
- Fallback capture (BPF/L2/L3) impl√©ment√© dans `packet_sniffer.py`.

### 4.5 Frontend

- **React 18** + **Vite 6**.
- **Recharts** (graphs), **React-Leaflet/Leaflet** (carte), **lucide-react** (icons).
- Proxy dev Vite : `/api` et `/ws` vers backend.

### 4.6 Reporting intelligent

- Pipeline analytique maison (`metrics_engine`, `trend_analysis`, `threat_index`).
- G√©n√©ration LLM via :
  - **Ollama** (par d√©faut),
  - ou endpoint compatible OpenAI (`openai.AsyncOpenAI`, ex. Groq).
- Exports : JSON, Markdown, PDF (fpdf2).

### 4.7 Conteneurisation

- `docker-compose.yml` : **3 services** orchestr√©s (PostgreSQL 16, Redis 7, Backend FastAPI).
- R√©seau Docker d√©di√© (`nds-network`) pour communication inter-services par nom DNS.
- Healthchecks sur les 3 services + `depends_on` avec conditions.
- `Dockerfile` backend bas√© sur `python:3.11-slim` + d√©pendances syst√®me (`libpcap`, `libpq`, `tcpdump`).
- `.dockerignore` pour optimiser le contexte de build.

---

## 5. Flux de donn√©es op√©rationnel

```mermaid
sequenceDiagram
    participant NIC as Interface reseau
    participant SNF as PacketSniffer
    participant FLW as FlowBuilder
    participant DET as DetectionService
    participant DB as PostgreSQL
    participant RED as Redis
    participant WS as WebSocket
    participant UI as Dashboard

    NIC->>SNF: Paquets IP
    SNF->>FLW: packet_info (src/dst/proto/flags/...)
    FLW->>FLW: Aggregation 5-tuple + timeout
    FLW-->>DET: Flows completes

    DET->>DET: Feature extraction + preprocessing
    DET->>DET: Predict supervise + non supervise
    DET->>DET: Fusion hybride + decision/severity

    DET->>DB: Persist flow + prediction + anomaly (+ alert si non-normal)
    DET->>RED: Publish alert + update threat score
    RED-->>WS: Message pub/sub
    WS-->>UI: Push alerte temps reel

    UI->>DB: Requetes dashboard via API
```

### 5.1 Transactions et persistances

Pour un flux analys√©, le backend persiste dans une transaction :
1. `network_flows`
2. `predictions`
3. `anomaly_scores`
4. `alerts` (conditionnel selon d√©cision)

### 5.2 Conditions de g√©n√©ration d‚Äôalerte

Une alerte est cr√©√©e si `decision != "normal"`.

---

## 6. Pipeline IA (inf√©rence uniquement)

### 6.1 Artefacts requis

R√©pertoire attendu : `ai/artifacts/`

- `model_supervised.keras`
- `model_unsupervised.keras`
- `scaler.pkl`
- `encoder.pkl`
- `feature_selector.pkl`
- `threshold_stats.pkl` *(utilis√© par le pr√©dicteur non supervis√© ; recommand√©)*

### 6.2 Cha√Æne de traitement

```mermaid
flowchart LR
    A[Flow reseau] --> B[FeatureExtractor]
    B --> C[DataValidator]
    C --> D[Scaler transform]
    D --> E[Feature Selector transform]
    E --> F[Supervised Predictor]
    E --> G[Unsupervised Predictor]
    F --> H[Hybrid Decision Engine]
    G --> H
    H --> I[Decision finale + severite + priorite]
```

### 6.3 Logique supervis√©e

Sortie principale :
- `attack_type`
- `probability`
- `is_attack` si :
  - classe pr√©dite ‚â† BENIGN/NORMAL/LEGITIMATE,
  - et probabilit√© ‚â• `min_classification_confidence` (config).

### 6.4 Logique non supervis√©e

- Calcul erreur de reconstruction MSE.
- Seuil dynamique prioritairement lu depuis `threshold_stats.pkl`.
- Si absent : fallback interne (`mean=0.01`, `std=0.005`).
- Score anomalie normalis√© √† partir du z-score.

### 6.5 Fusion hybride (d√©cision)

Poids par d√©faut (`ai/config/model_config.py`) :
- supervis√© = 0.50
- non supervis√© = 0.30
- r√©putation IP = 0.20

Forme de score :

$$
Risk = w_{sup}\cdot SupRisk + w_{unsup}\cdot AnomalyScore + w_{rep}\cdot Reputation
$$

avec bornage final dans $[0,1]$.

### 6.6 Matrice de d√©cision cod√©e

| is_attack (sup) | is_anomaly (unsup) | D√©cision r√©sultante |
|---|---|---|
| true | true | `confirmed_attack` |
| true | false | `confirmed_attack` si confiance ‚â• 0.8 sinon `suspicious` |
| false | true | `unknown_anomaly` |
| false | false | `suspicious` si risk ‚â• threshold_attack sinon `normal` |

### 6.7 S√©v√©rit√© et priorit√©

- S√©v√©rit√© mapp√©e sur le `final_risk_score` (`critical`, `high`, `medium`, `low`).
- Priorit√© op√©rationnelle calcul√©e selon couple (s√©v√©rit√©, d√©cision).

---

## 7. Module Reporting LLM

### 7.1 Vue d‚Äôensemble

Le reporting n‚Äôest pas un simple export statistique : il orchestre une pipeline compl√®te :
1. extraction m√©triques p√©riode,
2. calcul tendances vs p√©riode pr√©c√©dente,
3. calcul `threat_index` (0‚Äì100),
4. construction d‚Äôun prompt structur√© JSON-safe,
5. g√©n√©ration LLM,
6. formatage final (`json` / `markdown` / `pdf`).

```mermaid
flowchart LR
    A[Reporting API] --> B[metrics_engine]
    B --> C[trend_analysis]
    C --> D[threat_index]
    D --> E[prompt_builder]
    E --> F[llm_engine]
    F --> G[report_formatter]
    G --> H[pdf_exporter optionnel]
```

### 7.2 Endpoint de g√©n√©ration

`POST /api/reporting/generate`

Param√®tres query :
- `period_hours` (ex. 24, 168, 720)
- `detail_level` (`Technical` ou `Executive`)
- `export_format` (`json`, `markdown`, `pdf`)

### 7.3 Fournisseurs LLM support√©s

- **Ollama** par d√©faut (`LLM_PROVIDER=ollama`, endpoint `/api/generate`).
- **API OpenAI-compatible** via `openai.AsyncOpenAI` (ex. Groq).

### 7.4 Structure de sortie attendue du LLM

Le moteur exige un JSON contenant :
- `executive_summary`
- `technical_analysis`
- `attacker_behavior`
- `recommendations`

Fallback robuste appliqu√© si indisponibilit√© LLM ou JSON invalide.

---

## 8. Sch√©ma de donn√©es et persistance

### 8.1 Tables principales

- `network_flows`
- `predictions`
- `anomaly_scores`
- `alerts`
- `ip_geolocation`
- `model_versions`
- `feedback_labels`

### 8.2 Diagramme relationnel

```mermaid
erDiagram
    network_flows ||--o{ predictions : has
    network_flows ||--o{ anomaly_scores : has
    network_flows ||--o{ alerts : triggers
    alerts ||--o{ feedback_labels : receives

    network_flows {
        uuid id PK
        timestamp timestamp
        string src_ip
        string dst_ip
        int src_port
        int dst_port
        int protocol
        float duration
        jsonb raw_features
    }

    predictions {
        uuid id PK
        uuid flow_id FK
        string predicted_label
        float confidence
        jsonb class_probabilities
    }

    anomaly_scores {
        uuid id PK
        uuid flow_id FK
        float reconstruction_error
        float anomaly_score
        float threshold_used
        bool is_anomaly
    }

    alerts {
        uuid id PK
        uuid flow_id FK
        string severity
        string attack_type
        float threat_score
        string decision
        string status
        jsonb metadata
    }

    feedback_labels {
        uuid id PK
        uuid alert_id FK
        string analyst_label
        bool used_for_training
    }
```

### 8.3 Politique de r√©tention

Service actif au d√©marrage (`data_retention_service`) :
- suppression batch√©e des flux anciens,
- intervalle configurable,
- option de conservation des flux li√©s √† des alertes.

---

## 9. API backend (routes expos√©es)

### 9.1 Syst√®me

| M√©thode | Endpoint | Description |
|---|---|---|
| GET | `/` | Informations service |
| GET | `/health` | V√©rification API + DB + Redis |
| WS | `/ws/alerts` | Streaming temps r√©el des alertes |

### 9.2 D√©tection et capture (`/api/detection`)

| M√©thode | Endpoint | Description |
|---|---|---|
| POST | `/analyze` | Analyse d‚Äôun vecteur de features |
| GET | `/status` | √âtat du moteur de d√©tection |
| POST | `/capture/start` | D√©marrage capture r√©seau |
| POST | `/capture/stop` | Arr√™t capture r√©seau |
| GET | `/capture/status` | √âtat capture (paquets/flows/interface) |
| GET | `/capture/interfaces` | Interfaces r√©seau disponibles |
| POST | `/capture/interface` | Changement interface capture |

### 9.3 Alertes (`/api/alerts`)

| M√©thode | Endpoint | Description |
|---|---|---|
| GET | `/` | Liste alertes (filtres + pagination) |
| PATCH | `/{alert_id}/status` | Mise √† jour statut alerte |
| GET | `/stats` | Statistiques alertes |
| GET | `/top-ips` | Top IPs attaquantes |

### 9.4 Dashboard (`/api/dashboard`)

| M√©thode | Endpoint | Description |
|---|---|---|
| GET | `/overview` | KPI globaux |
| GET | `/attack-distribution` | R√©partition types attaques |
| GET | `/top-threats` | Top menaces |
| GET | `/recent-alerts` | Derni√®res alertes |
| GET | `/metrics` | Compteurs techniques |
| GET | `/traffic-timeseries` | S√©rie temporelle trafic |
| GET | `/protocol-distribution` | R√©partition protocoles |

### 9.5 G√©olocalisation (`/api/geo`)

| M√©thode | Endpoint | Description |
|---|---|---|
| GET | `/locate/{ip}` | G√©olocalisation IP unitaire |
| POST | `/locate-batch` | G√©olocalisation batch |
| GET | `/attack-map` | Donn√©es carte des attaques |
| GET | `/cached` | Cache g√©olocalisation |

### 9.6 Mod√®les (`/api/models`)

| M√©thode | Endpoint | Description |
|---|---|---|
| GET | `/status` | Pr√©sence des artefacts IA |
| GET | `/config` | Param√®tres inf√©rence expos√©s |

### 9.7 Feedback (`/api/feedback`)

| M√©thode | Endpoint | Description |
|---|---|---|
| POST | `/` | Soumission feedback analyste |
| GET | `/stats` | Compteur feedback non utilis√©s |
| GET | `/unused` | Listing feedback √† exploiter |

### 9.8 Reporting (`/api/reporting`)

| M√©thode | Endpoint | Description |
|---|---|---|
| POST | `/generate` | G√©n√©ration rapport SOC IA |

‚ö†Ô∏è Le routeur reporting est prot√©g√© par `X-API-Key` (`verify_api_key`).

---

## 10. Dashboard React (vues et int√©gration)

### 10.1 Vues impl√©ment√©es

- `overview` : KPI, threat score, trafic, alertes, timeline, carte.
- `alerts` : listing alertes.
- `traffic` : volumes + distributions + protocoles.
- `map` : carte des sources d‚Äôattaque.
- `reporting` : g√©n√©ration et export de rapports.
- `settings` : √©cran placeholder.

### 10.2 Int√©gration backend

- Base API front : `const API_BASE = '/api'`.
- Proxy Vite vers backend (`vite.config.js`) :
  - `/api` -> HTTP backend,
  - `/ws` -> WebSocket backend.

### 10.3 WebSocket temps r√©el

- Le frontend re√ßoit les alertes publi√©es Redis via `/ws/alerts`.
- Ping/Pong client pr√©vu (`ping` -> `pong`).

---

## 11. S√©curit√©, gouvernance et contraintes

### 11.1 M√©canismes pr√©sents

- Validation API key (`X-API-Key`) pour le module reporting.
- CORS configurable (`cors_origins` multi-domaines).
- Limiter SlowAPI initialis√© dans l‚Äôapplication.
- Validation stricte des features (NaN/Inf/outliers).
- Filtrage g√©olocalisation des IP priv√©es/r√©serv√©es.

### 11.2 Points d‚Äôattention

- L‚Äôauthentification API key n‚Äôest pas globalement appliqu√©e √† tous les routeurs, uniquement reporting.

- Le routeur reporting exige `X-API-Key` : pr√©voir son injection c√¥t√© frontend/proxy pour usage complet en UI.

---

## 12. Installation et ex√©cution

### 12.1 Pr√©requis

- **Docker Desktop** (obligatoire ‚Äî orchestre backend + PostgreSQL + Redis).
- **Node.js 18+** (pour le dashboard React).
- Windows : Npcap recommand√© pour capture Scapy en local.

### 12.2 Clonage

```bash
git clone https://github.com/meedvfx/Network-Defense-System.git
cd Network-Defense-System
```

### 12.3 D√©poser les artefacts IA (optionnel)

Placer les fichiers entra√Æn√©s dans `ai/artifacts/` (voir `docs/TRAINING_GUIDE.md`).  
Le backend d√©marre sans mod√®les (mode d√©grad√© ‚Äî pas d'inf√©rence IA).

### 12.4 Lancer le backend complet (Docker)

Une seule commande lance PostgreSQL, Redis et le backend FastAPI :

```bash
docker compose up --build -d
```

V√©rifier que tout est `healthy` :

```bash
docker compose ps
```

R√©sultat attendu :

| Conteneur | Port | √âtat |
|---|---|---|
| `nds-postgres` | 5432 | healthy |
| `nds-redis` | 6379 | healthy |
| `nds-backend` | 8000 | healthy |

> Le `docker-compose.yml` utilise `env_file: .env` et surcharge automatiquement `DB_HOST=postgres` et `REDIS_HOST=redis` pour le r√©seau Docker interne. Aucune configuration manuelle n'est n√©cessaire.

### 12.5 Lancer le dashboard (Frontend React)

```bash
cd dashboard
npm install
npm run dev
```

Le dashboard sera disponible sur `http://localhost:3000`.  
Le proxy Vite redirige automatiquement `/api/*` vers le backend (`http://localhost:8000`).

### 12.6 Acc√®s

| Service | URL |
|---|---|
| Dashboard React | `http://localhost:3000` |
| API Backend | `http://localhost:8000` |
| Swagger Docs | `http://localhost:8000/docs` |
| ReDoc | `http://localhost:8000/redoc` |
| Health Check | `http://localhost:8000/health` |
| Statut Mod√®les IA | `http://localhost:8000/api/models/status` |

### 12.7 Commandes utiles

```bash
# Voir les logs en temps r√©el
docker compose logs -f backend

# Arr√™ter tous les services
docker compose down

# Arr√™ter + supprimer les donn√©es (reset complet DB)
docker compose down -v

# Reconstruire apr√®s modification du code
docker compose up --build -d
```

### 12.8 Mode d√©veloppement local (sans Docker pour le backend)

Si vous pr√©f√©rez lancer le backend hors Docker (pour le debugging) :

```bash
# 1. Lancer uniquement DB + Redis via Docker
docker compose up postgres redis -d

# 2. Cr√©er et activer l'environnement Python
python -m venv .venv
# Windows:
.\.venv\Scripts\Activate.ps1
# Linux/macOS:
# source .venv/bin/activate

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. Lancer le backend
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

> En mode local, `.env` utilise `DB_HOST=localhost` et `REDIS_HOST=localhost` (valeurs par d√©faut), ce qui est correct.

---

## 13. Configuration environnement

Variables lues par le code (`backend/core/config.py` + `reporting/llm_engine.py`) :

### 13.1 Application

- `APP_NAME`
- `APP_ENV`
- `APP_DEBUG`
- `APP_HOST`
- `APP_PORT`
- `SECRET_KEY`

### 13.2 Base de donn√©es

- `DB_HOST`
- `DB_PORT`
- `DB_NAME`
- `DB_USER`
- `DB_PASSWORD`

### 13.3 Redis

- `REDIS_HOST`
- `REDIS_PORT`
- `REDIS_DB`

### 13.4 Capture r√©seau

- `CAPTURE_INTERFACE`
- `CAPTURE_BUFFER_SIZE`
- `CAPTURE_FLOW_TIMEOUT`

### 13.5 S√©curit√© API

- `API_KEY`
- `CORS_ORIGINS`
- `RATE_LIMIT_PER_MINUTE`

### 13.6 R√©tention

- `RETENTION_ENABLED`
- `RETENTION_FLOWS_DAYS`
- `RETENTION_RUN_INTERVAL_MINUTES`
- `RETENTION_DELETE_BATCH_SIZE`
- `RETENTION_KEEP_ALERTED_FLOWS`

### 13.7 Reporting LLM

- `LLM_PROVIDER` (`ollama`, `groq`, ...)
- `LLM_MODEL`
- `OLLAMA_BASE_URL`
- `${LLM_PROVIDER}_API_KEY` (ex. `GROQ_API_KEY`)

---

## 14. Observabilit√© et exploitation

### 14.1 Logging

Le module `monitoring/logger.py` fournit :
- console logging,
- fichier principal rotatif,
- fichier erreurs rotatif,
- fichier s√©curit√© (warnings+).

### 14.2 M√©triques

`monitoring/metrics.py` expose un collecteur de :
- compteurs (`packets_processed`, `flows_analyzed`, `alerts_generated`, ...),
- jauges (`current_threat_score`, `active_flows`, `buffer_usage`),
- sant√© syst√®me via `psutil` (CPU, RAM, disque, uptime).

### 14.3 Sant√© applicative

- endpoint `/health` avec checks DB et Redis.
- status capture via `/api/detection/capture/status`.

---

## 15. Limites connues et axes d‚Äôam√©lioration

### 15.1 Limites observ√©es

- Couverture s√©curit√© API partielle (reporting uniquement).
- Frontend reporting sans header `X-API-Key` explicite (√† traiter c√¥t√© int√©gration).
- Persistances `raw_features` actuellement optionnelles (`None` en √©criture de flux dans le path principal).

### 15.2 Axes techniques

- G√©n√©raliser authn/authz (RBAC/JWT/API Gateway).
- Ajouter tests d‚Äôint√©gration API/DB/Redis/WS.
- Industrialiser MLOps offline (versionning mod√®le, validation automatique artefacts, CI/CD de promotion).

---

## 16. Documentation compl√©mentaire

- Probl√©matique projet : `docs/PROBLEM_STATEMENT.md`
- Guide entra√Ænement offline : `docs/TRAINING_GUIDE.md`
- Guide utilisateur dashboard : `docs/USER_GUIDE.md`

---

## 17. Licence

Projet sous licence **MIT** (`LICENSE`).

---

### R√©sum√© d‚Äôalignement code

Ce README d√©crit fid√®lement l‚Äôimpl√©mentation actuelle du d√©p√¥t :
- routes r√©ellement mont√©es dans `backend/main.py`,
- pipeline IA r√©ellement ex√©cut√© dans `backend/services/detection_service.py`,
- sch√©ma et op√©rations repository du dossier `backend/database/`,
- reporting LLM et exports du dossier `reporting/`,
- vues frontend pr√©sentes dans `dashboard/src/App.jsx`,
- Docker Compose orchestrant les 3 services (PostgreSQL, Redis, Backend).
